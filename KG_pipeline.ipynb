{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Knowledge Graph from the output of the NER & RE models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions on how to work with Neo4j alongside this code\n",
    "\n",
    "Before you start, download neo4j desktop from https://neo4j.com/download/\n",
    "\n",
    "Then, create a project called \"Text_Mining\" (or whatever name you want, since this name is not used within this code). \n",
    "\n",
    "Click \"Add\" -> \"Local DMBS\" and name it \"Text_Mining_Neo4j\" (even though this name is also not used within this code) while setting the password to \"bilalbroski1\" (IMPORTANT!)\n",
    "\n",
    "Then you have to click the blue \"Start\" button and wait for the server to start. After it is done loading, click the blue \"Open\" button. This will cause the Neo4j Browser to open. \n",
    "\n",
    "In Neo4j browser, run the command \"MATCH (n) RETURN n\" to show the complete KG, and run \"MATCH (n) DETACH DELETE n\" to completely empty the DMBS.\n",
    "\n",
    "If any of this does not work, follow the steps in the \"Download Neo4j\" section of https://youtu.be/8jNPelugC2s?si=QV898-ggdLIq9XPk&t=597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, os.path\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from unidecode import unidecode\n",
    "from num2words import num2words\n",
    "import pickle\n",
    "# from copy import deepcopy\n",
    "\n",
    "# imports for loading the NER model using flair\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-31 23:17:57,329 SequenceTagger predicts: Dictionary with 10 tags: O, PLAYER, BIRTHDATE, COUNTRY, NATIONALITY, POSITION, CLUB, REFERENCE, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# load the NER model\n",
    "custom_ner_model = SequenceTagger.load(r'flair_models\\best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for loading texts\n",
    "\n",
    "# set to True in case you want to select a single specific text\n",
    "select_text = True\n",
    "\n",
    "# index of the specific text that you want to select\n",
    "text_i = 369  # index of text for Thomas Alun Lockyer = 192; Mark Maria Hubertus Flekken = 369\n",
    "\n",
    "# if select_text is set to False, there will be nr_texts selected\n",
    "nr_texts = 2 # max number of texts is 1031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text with index number 369 has successfully been imported\n",
      "['Mark Maria Hubertus Flekken (born 13 June 1993) is a Dutch professional footballer who plays as a goalkeeper for Premier League club Brentford and the Netherlands national team.Early years.Flekken grew up in Bocholtz, Limburg, Netherlands on the German border. His parents René and Annie used to play football themselves, and his younger brother Roy also became a goalkeeper. Club career.']\n"
     ]
    }
   ],
   "source": [
    "# import the texts that have to be converted into a KG (=Knowledge Graph)\n",
    "\n",
    "# Create empty list to which the text(s) can be added\n",
    "texts = []\n",
    "\n",
    "if select_text: # only select the text with index text_i\n",
    "    with open(f'./data/footballer_{text_i}.txt', 'r') as f:\n",
    "        contents = f.read()\n",
    "        texts.append(contents)\n",
    "    f.close()\n",
    "    print(f\"The text with index number {text_i} has successfully been imported\")\n",
    "\n",
    "else: # select the first nr_texts texts\n",
    "    for i in range(nr_texts):\n",
    "        with open(f'./data/footballer_{i}.txt', 'r') as f:\n",
    "            contents = f.read()\n",
    "            texts.append(contents)\n",
    "        f.close()\n",
    "\n",
    "    print(f\"{len(texts)} texts have been successfully imported\")\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_text(sentence):\n",
    "    '''\n",
    "    Uses the entity predictions from the NER model to augment the text with entity tags.\n",
    "    '''\n",
    "    outp = sentence.text\n",
    "    used_text = []\n",
    "    for l in sentence.labels:\n",
    "        text_token = l.labeled_identifier\n",
    "        text_token = text_token.split()\n",
    "        text, token = text_token[1].split('/')\n",
    "        text = text.replace('\"', '')\n",
    "        if text not in used_text:\n",
    "            outp = outp.replace(text, f'[{token}]{text}[{token}]')\n",
    "            outp = outp.replace(f'[{token}] [{token}]', ' ')\n",
    "            used_text.append(text)\n",
    "        else: \n",
    "            continue\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PLAYER]Mark Maria Hubertus Flekken[PLAYER] (born [BIRTHDATE]13 June 1993[BIRTHDATE]) is a [NATIONALITY]Dutch[NATIONALITY] professional footballer who plays as a [POSITION]goalkeeper[POSITION] for Premier League club [CLUB]Brentford[CLUB] and the [COUNTRY]Netherlands[COUNTRY] national team.Early years.[PLAYER]Flekken[PLAYER] grew up in Bocholtz, Limburg, [COUNTRY]Netherlands[COUNTRY] on the German border. [REFERENCE]His[REFERENCE] parents René and Annie used to play football themselves, and his younger brother [PLAYER]Roy[PLAYER] also became a [POSITION]goalkeeper[POSITION]. Club career.']\n"
     ]
    }
   ],
   "source": [
    "# Perform NER on all texts to create a list with the texts in augmented form\n",
    "augmented_texts = [] # Create empty list to append the augmented texts to\n",
    "\n",
    "for text in texts: \n",
    "    sentence = Sentence(str(text))\n",
    "    custom_ner_model.predict(sentence)\n",
    "    augmented_sentence = augmented_text(sentence)\n",
    "    augmented_texts.append(augmented_sentence)\n",
    "\n",
    "print(augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escapeRegExp(text):\n",
    "    \"\"\"\n",
    "    Replace all of the opening brackets with \"\\[\" to escape the special characters in the regrex.\n",
    "    This is required to prevent unterminated character sets.\n",
    "    If the unterminated character sets error still occurs, try running the commented out lines as well.\n",
    "    Source: https://stackoverflow.com/questions/54135606/python-re-error-unterminated-character-set-at-position\n",
    "    \"\"\"\n",
    "    edited_text = text.replace(\"[\", \"\\[\")\n",
    "    # edited_text = edited_text.replace(\"{\", \"\\{\")\n",
    "    # edited_text = edited_text.replace(\"(\", \"\\(\")\n",
    "    # edited_text = edited_text.replace(\")\", \"\\)\")\n",
    "    return edited_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_texts = map(escapeRegExp, augmented_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_texts2 = map(escapeRegExp, augmented_texts)\n",
    "# for i in final_texts2:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_var_name(var_name: str):\n",
    "    \"\"\"\n",
    "    Check string for violations of the Cypher variable name conventions,\n",
    "    namely that it must always start with a letter.\n",
    "    If the string starts with an integer, replace it with the word for this integer.\n",
    "    For example, 2_october becomes two_october.\n",
    "    Returns False if the string satisfies the naming conventions.\n",
    "    \"\"\"\n",
    "    if len(var_name)==1: # Unhandable case\n",
    "        return False\n",
    "\n",
    "    if len(var_name) > 0 and var_name[0].isdigit(): # this condition might cause the original error to occur again!!\n",
    "        i_final_int = 0 # starts at zero to prevent index out of range error from occuring at var_name[i_final_int].isdigit() in the while statement\n",
    "        \n",
    "        while ( var_name[i_final_int].isdigit() ) and ( i_final_int < len(var_name) -1 ):\n",
    "            i_final_int += 1\n",
    "        \n",
    "        if i_final_int > 0:\n",
    "            var_name = num2words( var_name[ : i_final_int] ) + var_name[i_final_int : ]\n",
    "            \n",
    "    return var_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate creation of Cypher CREATE query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entity_query(augmented_texts: list, suppress_warnings: bool=True):\n",
    "    \"\"\"\n",
    "    Creates a Cypher query that creates the entity part of a Neo4j Database \n",
    "    using the entities from the augmented_texts list.\n",
    "    \n",
    "    Inputs:\n",
    "    - augmented_texts: list containing the annotated texts that have to be converted into a KG\n",
    "    - suppress_warnings: If True, the warnings about texts that the function skips over will be suppressed.\n",
    "\n",
    "    Assumptions: \n",
    "    - If entity tags are nested, this is never with a depth higher than 1. This means that the\n",
    "        nested entities should always be of the shape \"[TAG_1]entity1_pt1 [TAG_2]entity2[TAG2] entity1_pt1[TAG_1]\"\n",
    "    \n",
    "    Output: \n",
    "    - Each query-line has the following format: (variable_name:ENTITY_TAG{name: 'name'})\n",
    "    - In this format, each variable_name is completely decapitalized and all \n",
    "        whitespaces have been replaced by underscores.\n",
    "    - the name that is within the curly brackets of each entity has each individual word capitalized, \n",
    "        but that is the only preprocessing performed on it.\n",
    "    \"\"\"\n",
    "    # initialise a set to which all query-strings are added, and that can later be concatenated into a single string.\n",
    "    # This helps preventing duplicates\n",
    "    query_set = set()\n",
    "    # initialise variable that prevents a closing tag from being investigated by skipping the next iteration of the current for loop if it equals True\n",
    "    skip_iteration = False \n",
    "    # initialise variable that skips over an entire nested tag structure after it has been analyzed\n",
    "    skip_nested_structure = 0 \n",
    "\n",
    "    for text in augmented_texts:\n",
    "\n",
    "        # Find all of the opening brackets in the text\n",
    "        brackets_open = [m.start() for m in re.finditer(\"\\\\[\", text)]\n",
    "        # Find all of the closing brackets in the text\n",
    "        brackets_close = [m.start() for m in re.finditer(\"]\", text)]\n",
    "\n",
    "        if (len(brackets_open) % 2 > 0) or (len(brackets_close) % 2 > 0):\n",
    "            if not suppress_warnings:\n",
    "                print(f\"An uneven number of brackets has been found! Namely length of BO = {len(brackets_open)} or length of BC = {len(brackets_close)}\")\n",
    "            continue\n",
    "            \n",
    "        if len(brackets_open) != len(brackets_close):\n",
    "            if not suppress_warnings:\n",
    "                print(f\"There is an unequal number of opening and closing brackets! There is {len(brackets_open)} opening brackets, and {len(brackets_close)} closing brackets.\")\n",
    "            continue\n",
    "\n",
    "        # Loop over each tag to create query lines for the entities they annotate, while accounting for nested tags.\n",
    "        for i in range( len(brackets_open) -1 ): # -1 is to prevent the function from finding a next pair of brackets when arriving at the final pair of brackets\n",
    "\n",
    "            # skip this iteration if the previous non-nested (opening) tag has already been investigated\n",
    "            if skip_iteration:\n",
    "                skip_iteration = False\n",
    "                continue\n",
    "            \n",
    "            # skip this iteration if the current tag is part of an already investigated nested structure\n",
    "            if skip_nested_structure:\n",
    "                skip_nested_structure -= 1\n",
    "                continue\n",
    "\n",
    "            io = brackets_open[i] # index of opening bracket of the entity tag that is currently being looped over\n",
    "            ic = brackets_close[i] # index of closing bracket of the entity tag that is currently being looped over\n",
    "            opening_tag = text[io+1:ic] # find the opening tag\n",
    "\n",
    "            # initialise the variables that are required when working with a nested tag\n",
    "            io_next = -1 # index of the opening bracket of the tag that is under investigation in the while statement\n",
    "            ic_next = -1 # index of the closing bracket of the tag that is under investigation in the while statement\n",
    "            ie_tags = [] # initialise a list where the indices of the brackets of the inner entities' tags can be stored\n",
    "                         # ie_tags[0][0] = opening bracket index of ie opening tag; \n",
    "                         # ie_tags[1][1] = closing bracket index of ie closing tag\n",
    "            closing_tag = None # initialise the closing tag that we are trying to find\n",
    "            next_tag = None # initialise the variable that finds the closing tag \n",
    "            # initialise variable that keeps track if the tag that is currently under investigation is a nested one\n",
    "            is_nested = -1 # current tag is nested if is_nested > 0\n",
    "            j = i+1 # initialise index to use in the while statement \n",
    "            \n",
    "            while ( next_tag != opening_tag ) and ( j < len(brackets_open) - 1 ) :\n",
    "                closing_tag = next_tag # Set the closing tag to the tag that was investigated in the previous loop of the while statement\n",
    "                io_next = brackets_open[j] \n",
    "                ic_next = brackets_close[j]\n",
    "                next_tag = text[io_next+1:ic_next]\n",
    "\n",
    "                # Remember the indices of the brackets of the inner entities' tags\n",
    "                ie_tags.append( [io_next, ic_next] ) \n",
    "\n",
    "                is_nested += 1\n",
    "                j += 1\n",
    "\n",
    "            if is_nested > 2 :\n",
    "                if not suppress_warnings:\n",
    "                    print(f\"A tag has been encountered that is nested on more than a single level! It is located in between indices {io_next} and {ic_next}.\")\n",
    "                continue\n",
    "\n",
    "            if is_nested > 0: # if the current tag is a nested tag\n",
    "                # Explanation of used terminology: the inner entity (ie) is the entity that is nested within the outer entity (oe)\n",
    "\n",
    "                # find the indices of the inner entity (ie)\n",
    "                begin_ie = ie_tags[0][1] + 1 # index of the first letter of the inner entity\n",
    "                end_ie = ie_tags[1][0] - 1 # index of the last letter of the inner entity\n",
    "                \n",
    "                # extract the inner entity (ie)\n",
    "                inner_entity = text[ begin_ie: end_ie ].strip() \n",
    "                ie_variable = inner_entity.replace(\" \", \"_\").lower() \n",
    "                ie_variable = fix_var_name(ie_variable)\n",
    "                inner_entity = inner_entity.lower().title()\n",
    "                # inner_entity = fix_var_name(inner_entity)\n",
    "                # if the unhandable case happens where an entity has length 1, continue\n",
    "                if not inner_entity:\n",
    "                    continue\n",
    "\n",
    "                # find the indices of the outer entity (oe)\n",
    "                begin_oe = io + (len(opening_tag) + 2) # index of the first letter of the outer entity\n",
    "                end_oe = brackets_open[i+3] - 2 # index of the last letter of the outer entity\n",
    "                ie_ot = brackets_open[i+1] - 1 # index of the ie opening tag (=ie_ot)\n",
    "                ie_ct = brackets_close[i+2] + 1 # index of the ie closing tag (=ie_ct)\n",
    "                # extract the outer entity (oe)\n",
    "                outer_entity = text[ begin_oe : ie_ot ] + inner_entity + text[ ie_ct : end_oe + 1 ].strip() \n",
    "                oe_variable = outer_entity.replace(\" \", \"_\").lower()\n",
    "                oe_variable = fix_var_name(oe_variable)\n",
    "                outer_entity = outer_entity.lower().title()\n",
    "                # outer_entity = fix_var_name(outer_entity)\n",
    "\n",
    "                # if the unhandable case happens where an entity has length 1, continue\n",
    "                if (not ie_variable) or (not oe_variable): # or (not outer_entity):\n",
    "                    continue\n",
    "\n",
    "                # Create a Cypher-queriable line that can be used to add this entity to the KG\n",
    "                query_line_oe = f\"({unidecode(oe_variable)}:{opening_tag}{{name: '{unidecode(outer_entity)}'}})\" \n",
    "                query_set.add(query_line_oe) # add the query line to the set of all query lines that are going to be added to the KG\n",
    "                query_line_ie = f\"({unidecode(ie_variable)}:{closing_tag}{{name: '{unidecode(inner_entity)}'}})\" \n",
    "                query_set.add(query_line_ie) # add the query line to the set of all query lines that are going to be added to the KG\n",
    "\n",
    "                # Make sure the current for loop skips over the remaining 3 tags from the current nested structure\n",
    "                skip_nested_structure = 3 \n",
    "\n",
    "            else: # if the current tag is not a nested one\n",
    "\n",
    "                # extracting the name of the entity \n",
    "                begin_entity = io + (len(opening_tag) + 2) # index of the first letter of the entity\n",
    "                end_entity = brackets_close[i+1] - (len(opening_tag) + 2) # index of the last letter of the entity\n",
    "                entity = text[ begin_entity : end_entity  ].strip()\n",
    "                entity_variable = entity.replace(\" \", \"_\").lower()\n",
    "                entity_variable = fix_var_name(entity_variable)\n",
    "                # if the unhandable case happens where an entity has length 1, continue\n",
    "                if not entity_variable:\n",
    "                    continue\n",
    "                entity = entity.lower().title()\n",
    "                # entity = fix_var_name(entity)\n",
    "                # # if the unhandable case happens where an entity has length 1, continue\n",
    "                # if not entity:\n",
    "                #     continue\n",
    "\n",
    "                # Create a Cypher-queriable line that can be used to add this entity to the KG\n",
    "                query_line = f\"({unidecode(entity_variable)}:{opening_tag}{{name: '{unidecode(entity)}'}})\" \n",
    "                # print('query_line:', query_line)\n",
    "                query_set.add(query_line) # add the query line to the set of all query lines that are going to be added to the KG\n",
    "\n",
    "                # skip the next iteration of the current for loop to prevent a closing tag from being investigated\n",
    "                skip_iteration = True\n",
    "\n",
    "    return query_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running create_entity_query on the first 10 texts of the dataset\n",
    "query_set_NER = create_entity_query(final_texts, suppress_warnings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "{\"(brentford:CLUB{name: 'Brentford'})\", \"(dutch:NATIONALITY{name: 'Dutch'})\", \"(flekken:PLAYER{name: 'Flekken'})\", \"(netherlands:COUNTRY{name: 'Netherlands'})\", \"(goalkeeper:POSITION{name: 'Goalkeeper'})\", \"(roy:PLAYER{name: 'Roy'})\", \"(mark_maria_hubertus_flekken:PLAYER{name: 'Mark Maria Hubertus Flekken'})\", \"(thirteen_june_1993:BIRTHDATE{name: '13 June 1993'})\", \"(his:REFERENCE{name: 'His'})\"}\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "print(len(query_set_NER))\n",
    "print(query_set_NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Knowledge Graph in Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the RE part of the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the output from the RE model\n",
    "RE_data_path = \"C:/Users/guusj/Documents/AAA_Master_DSAI/Y2Q1/2AMM30_Text_Mining/DATA/test_RE_output_flekken\"\n",
    "# RE_data_path = \"./test_RE_output_flekken\"\n",
    "with open(RE_data_path, \"rb\") as fp:\n",
    "    re_output = pickle.load(fp)\n",
    "\n",
    "# preprocess the variable names of the entities within data. \n",
    "# The variable names of the relationships already exist in the correct form\n",
    "for i in range(len(re_output)):\n",
    "    \n",
    "    old_relation = re_output[i]\n",
    "\n",
    "    # perform preprocessing\n",
    "    new_relation_0 = old_relation[0].strip().replace(\" \", \"_\").lower()\n",
    "    new_relation_2 = old_relation[2].strip().replace(\" \", \"_\").lower()\n",
    "\n",
    "    # Make sure the imported variable names comply with the naming restrcitions of Cypher\n",
    "    new_relation_0 = fix_var_name(new_relation_0)\n",
    "    new_relation_2 = fix_var_name(new_relation_2)\n",
    "\n",
    "    # Combine all new entries into a tuple and use it to replace the old tuple\n",
    "    new_relation = (new_relation_0, old_relation[1], new_relation_2)\n",
    "    re_output[i] = new_relation\n",
    "\n",
    "# convert the re_output list into a set\n",
    "re_output = set(re_output)\n",
    "# show results\n",
    "# re_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relation_query(relations_set: set):\n",
    "    \"\"\"\n",
    "    Creates a Cypher query that creates the relation/RE part of a Neo4j Database \n",
    "    \n",
    "    Assumptions: \n",
    "    - relations_set is of shape: set((SUBJECT, relationship, OBJECT), ... ), where SUBJECT and OBJECT are variables \n",
    "        referring to entities and are contained within a tuple.\n",
    "    - THE SUBJECTS, RELATIONSHIPS, AND OBJECTS HAVE THE SAME SHAPE/FORMAT AS IN THE NER MODEL, so\n",
    "        - all have been unidecoded\n",
    "        - subjects and objects have been stripped of leading and trailing whitespaces, are \n",
    "            completely in lowercase, and all leftover whitespaces have been replaced by underscores\n",
    "    \"\"\"\n",
    "    # initialise a set to which all query-strings are added, and that can later be concatenated into a single string.\n",
    "    # This helps preventing duplicates\n",
    "    query_set = set()\n",
    "\n",
    "    for s in relations_set:\n",
    "        \n",
    "        subj = s[0].replace(\"'\", \"\")\n",
    "        # print(s)\n",
    "        relation = s[1]\n",
    "        obj = s[2].replace(\"'\", \"\")\n",
    "\n",
    "        query_line = f\"({ unidecode(subj) })-[:{ relation }]->({ unidecode(obj) })\" \n",
    "        query_set.add(query_line) # add the query line to the set of all query lines that are going to be added to the KG\n",
    "\n",
    "    return query_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(mark_maria_hubertus_flekken)-[:born]->(thirteen_june_1993)',\n",
       " '(mark_maria_hubertus_flekken)-[:has_nationality]->(dutch)',\n",
       " '(mark_maria_hubertus_flekken)-[:originates_from]->(netherlands)',\n",
       " '(mark_maria_hubertus_flekken)-[:played_for]->(alemannia_aachen)',\n",
       " '(mark_maria_hubertus_flekken)-[:played_for]->(flekken)',\n",
       " '(mark_maria_hubertus_flekken)-[:played_for]->(greuther_furth)',\n",
       " '(mark_maria_hubertus_flekken)-[:plays_as]->(goalkeeper)',\n",
       " '(mark_maria_hubertus_flekken)-[:plays_for]->(brentford)'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_set_RE = create_relation_query(re_output)\n",
    "# Show results\n",
    "query_set_RE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Final Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_queries(query_set_NER: set, query_set_RE: set):\n",
    "    \"\"\"\n",
    "    Concatenate all of the query lines containing the named entities together with the query lines\n",
    "    containing the relationships, in order to form one final Cypher query that can be ran to \n",
    "    create the KG.\n",
    "    \"\"\"\n",
    "    # Concatenate all of the query lines to form one final Cypher query that creates the KG\n",
    "    cqlCreate = \"\"\"CREATE\"\"\"\n",
    "\n",
    "    # add the entities from the NER set\n",
    "    for i, line1 in enumerate(query_set_NER):\n",
    "        if not i: # the first query entry should not be seperated from the CREATE statement with a comma\n",
    "            cqlCreate = cqlCreate + ' \\n' + line1\n",
    "        else:\n",
    "            cqlCreate = cqlCreate + ',\\n' + line1\n",
    "\n",
    "    # add the relationships from the RE set\n",
    "    for j, line2 in enumerate(query_set_RE):\n",
    "        if j == (len(query_set_RE)-1): # The final entry of the query should end with a semicolon\n",
    "            cqlCreate = cqlCreate + ',\\n' + line2 + ';'\n",
    "        else:\n",
    "            cqlCreate = cqlCreate + ',\\n' + line2\n",
    "\n",
    "    return cqlCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE \\n(brentford:CLUB{name: 'Brentford'}),\\n(dutch:NATIONALITY{name: 'Dutch'}),\\n(flekken:PLAYER{name: 'Flekken'}),\\n(netherlands:COUNTRY{name: 'Netherlands'}),\\n(goalkeeper:POSITION{name: 'Goalkeeper'}),\\n(roy:PLAYER{name: 'Roy'}),\\n(mark_maria_hubertus_flekken:PLAYER{name: 'Mark Maria Hubertus Flekken'}),\\n(thirteen_june_1993:BIRTHDATE{name: '13 June 1993'}),\\n(his:REFERENCE{name: 'His'}),\\n(mark_maria_hubertus_flekken)-[:played_for]->(alemannia_aachen),\\n(mark_maria_hubertus_flekken)-[:played_for]->(flekken),\\n(mark_maria_hubertus_flekken)-[:originates_from]->(netherlands),\\n(mark_maria_hubertus_flekken)-[:has_nationality]->(dutch),\\n(mark_maria_hubertus_flekken)-[:plays_for]->(brentford),\\n(mark_maria_hubertus_flekken)-[:played_for]->(greuther_furth),\\n(mark_maria_hubertus_flekken)-[:born]->(thirteen_june_1993),\\n(mark_maria_hubertus_flekken)-[:plays_as]->(goalkeeper);\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cqlCreate = combine_queries(query_set_NER, query_set_RE)\n",
    "# Show results\n",
    "cqlCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Knowledge Graph in Neo4j using Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Credentials\n",
    "\n",
    "uri = \"bolt://localhost:7687\" # Click the copy button in the \"Bolt port\" row from the table that appears when you click NBA_example in Neo4j Desktop\n",
    "userName = \"neo4j\"\n",
    "password = \"bilalbroski1\" # password for Text_Mining_Neo4j DBMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the neo4j database server\n",
    "graphDB_Driver = GraphDatabase.driver(uri, auth=(userName, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable that should be set to \"True\" when the CREATE query has to be run\n",
    "# The reason why this variable exists, is that if you run the code multiple times \n",
    "# with create_DB set to True, there will be a lot of duplicates within Neo4j\n",
    "create_DB = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a few queries to test the Knowledge Graph with after it has been created\n",
    "\n",
    "# CQL (=Cypher Query Language) to query all players that played for the Dutch national team\n",
    "cqlNationalTeamQuery = \"\"\"MATCH (player:PLAYER) -[:played_for] -> (country:COUNTRY) \n",
    "WHERE country.name = \"Netherlands\"\n",
    "RETURN player.name\n",
    "\"\"\"\n",
    "# CQL (=Cypher Query Language) to query all players that play as goalkeeper\n",
    "cqlGoalkeeperQuery = \"\"\"MATCH (player:PLAYER) -[:plays_as] -> (position:POSITION) \n",
    "WHERE position.name = \"Goalkeeper\"\n",
    "RETURN player.name\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE \\n(brentford:CLUB{name: 'Brentford'}),\\n(dutch:NATIONALITY{name: 'Dutch'}),\\n(flekken:PLAYER{name: 'Flekken'}),\\n(netherlands:COUNTRY{name: 'Netherlands'}),\\n(goalkeeper:POSITION{name: 'Goalkeeper'}),\\n(roy:PLAYER{name: 'Roy'}),\\n(mark_maria_hubertus_flekken:PLAYER{name: 'Mark Maria Hubertus Flekken'}),\\n(thirteen_june_1993:BIRTHDATE{name: '13 June 1993'}),\\n(his:REFERENCE{name: 'His'}),\\n(mark_maria_hubertus_flekken)-[:played_for]->(alemannia_aachen),\\n(mark_maria_hubertus_flekken)-[:played_for]->(flekken),\\n(mark_maria_hubertus_flekken)-[:originates_from]->(netherlands),\\n(mark_maria_hubertus_flekken)-[:has_nationality]->(dutch),\\n(mark_maria_hubertus_flekken)-[:plays_for]->(brentford),\\n(mark_maria_hubertus_flekken)-[:played_for]->(greuther_furth),\\n(mark_maria_hubertus_flekken)-[:born]->(thirteen_june_1993),\\n(mark_maria_hubertus_flekken)-[:plays_as]->(goalkeeper);\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the CQL query to create the KG\n",
    "if create_DB:\n",
    "    with graphDB_Driver.session() as graphDB_Session:\n",
    "        # Create nodes\n",
    "        graphDB_Session.run(cqlCreate)\n",
    "\n",
    "# Show the query that we ran again\n",
    "cqlCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of all football players that have played for the Dutch national team:\n",
      "\n",
      "\n",
      "Names of players that play as goalkeepers:\n",
      "<Record player.name='Mark Maria Hubertus Flekken'>\n"
     ]
    }
   ],
   "source": [
    "# Execute all other CQL queries and print the results\n",
    "with graphDB_Driver.session() as graphDB_Session:\n",
    "    # Query the graph #1\n",
    "    dutch_players = graphDB_Session.run(cqlNationalTeamQuery)\n",
    "\n",
    "    print(\"Names of all football players that have played for the Dutch national team:\")\n",
    "    for player in dutch_players:\n",
    "        print(player)\n",
    "\n",
    "    # Query the graph #2\n",
    "    goalkeepers = graphDB_Session.run(cqlGoalkeeperQuery)\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Names of players that play as goalkeepers:\")\n",
    "    for player in goalkeepers:\n",
    "        print(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix with helpful explanations / code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of helpful Cypher commands:\n",
    "- To show the complete KG: \n",
    "    - MATCH (n) RETURN n\n",
    "- To delete the complete KG:\n",
    "    - MATCH (n) DETACH DELETE n\n",
    "\n",
    "For an example of what a Python query to create a KG in Cypher/Neo4j should look like: https://github.com/harblaith7/Neo4j-Crash-Course/blob/main/01-initial-data.cypher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find index:\n",
    "\n",
    "If you want to know which index a certain text has within the dataset,you can enter the name that starts the text as a string to the begin_str variable.\n",
    "\n",
    "\n",
    "The following code will then print the index of the text that begins like this when you run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the text that starts with 'Mark Maria Hubertus Flekken' is:  369\n"
     ]
    }
   ],
   "source": [
    "# Define the number of players/texts\n",
    "nr_texts = 1031 # set to max number of texts (1031) since you want to search all of these\n",
    "\n",
    "# begin_str = \"Thomas Alun Lockyer\"\n",
    "begin_str = \"Mark Maria Hubertus Flekken\"\n",
    "\n",
    "for i in range(nr_texts):\n",
    "    with open(f'./data/footballer_{i}.txt', 'r') as f:\n",
    "        contents = f.read()\n",
    "        # texts.append(contents)\n",
    "        if (contents[:len(begin_str)] == begin_str):\n",
    "            print(f\"The index of the text that starts with '{begin_str}' is: \", i)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2amm30",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
